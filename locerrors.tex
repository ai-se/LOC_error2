\documentclass[final,twocolumn,5p]{elsarticle}
% \documentclass{sig-alternative}
% \documentclass[conference]{IEEEtran}
% \documentclass[smallextended]{svjour3}
% \documentclass[preprint,12pt,3p,number]{elsarticle}
\usepackage{multirow}
% \usepackage{natbib}
\usepackage{color}
\usepackage{graphics} 
% \usepackage{cite}
\usepackage{rotating}
\usepackage{eqparbox}
\usepackage{graphics}
\usepackage{colortbl} 
%\usepackage{times}
 \usepackage{mathptmx} \usepackage[scaled=.90]{helvet} \usepackage{courier}
\usepackage{balance}
\usepackage{picture}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[export]{adjustbox}
\renewcommand{\footnotesize}{\scriptsize}
\definecolor{lightgray}{gray}{0.8}
\definecolor{darkgray}{gray}{0.6}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
%%% graph
\newcommand{\crule}[3][darkgray]{\textcolor{#1}{\rule{#2}{#3}}}
%\newcommand{\rone}{\crule{1mm}{1.95mm}}
%\newcommand{\rtwo}{\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}}
%\newcommand{\rthree}{\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}}
%\newcommand{\rfour}{\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}} 
%\newcommand{\rfive}{\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}\hspace{0.3pt}\crule{1mm}{1.95mm}}
\newcommand{\quart}[3]{\begin{picture}(100,6)%1
{\color{black}\put(#3,3){\circle*{4}}\put(#1,3){\line(1,0){#2}}}\end{picture}}
\definecolor{Gray}{gray}{0.95}
\definecolor{LightGray}{gray}{0.975}
% \newcommand{\rone}{}
% \newcommand{\rtwo}{}
% \newcommand{\rthree}{}
% \newcommand{\rfour}{} 
% \newcommand{\rfive}{}
\newcommand{\wei}[1]{\textcolor{red}{Wei: #1}} 
\newcommand{\Menzies}[1]{\textcolor{red}{Dr.Menzies: #1}} 

%% timm tricks
\newcommand{\bi}{\begin{itemize}[leftmargin=0.4cm]}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\tion}[1]{\S\ref{sect:#1}}
\newcommand{\fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\tab}[1]{Table~\ref{tab:#1}}
\newcommand{\eq}[1]{Equation~\ref{eq:#1}}

%% space saving measures

\usepackage[shortlabels]{enumitem}  
\usepackage{url}
% \def\baselinestretch{1}


% \setlist{nosep}
%  \usepackage[font={small}]{caption, subfig}
% \setlength{\abovecaptionskip}{1ex}
%  \setlength{\belowcaptionskip}{1ex}

%  \setlength{\floatsep}{1ex}
%  \setlength{\textfloatsep}{1ex}
%  \newcommand{\subparagraph}{}

% \usepackage[compact,small]{titlesec}
% \DeclareMathSizes{7}{7}{7}{7} 
% \setlength{\columnsep}{7mm}


\usepackage{graphicx}
\usepackage{multirow}
\usepackage[svgnames]{xcolor}
\usepackage[framed]{ntheorem}
\usepackage{framed}
\usepackage{tikz}
\usetikzlibrary{shadows}
%\newtheorem{Lesson}{Lesson}
\theoremclass{Lesson}
\theoremstyle{break}

% inner sep=10pt,
\tikzstyle{thmbox} = [rectangle, rounded corners, draw=black,
  fill=Gray!20,  drop shadow={fill=black, opacity=1}]
\newcommand\thmbox[1]{%
  \noindent\begin{tikzpicture}%
  \node [thmbox] (box){%
\begin{minipage}{.94\textwidth}%    
      \vspace{-3mm}#1\vspace{-3mm}%
    \end{minipage}%
  };%
  \end{tikzpicture}}

\let\theoremframecommand\thmbox
\newshadedtheorem{lesson}{Result}
\begin{document}
\begin{frontmatter}
\title{ Impacts of Bad ESP (Early Size Predictions) on Software Effort Estimation}
\author{George Mathew\corref{cor1}}
\ead{george.meg91@gmail.com}
\author{Tim Menzies}
\ead{tim.menzies@gmail.com}
\author{Jairus Hihn}
\ead{ jairus.m.hihn@jpl.nasa.gov}
\cortext[cor1]{Corresponding author: Tel:XXX(Wei)}
\address{Department of Computer Science, North Carolina State University, Raleigh, NC, USA,\\
Jet Propulsion Laboratory, Pasadena, CA}



% % \numberofauthors{1}
% \author{Wei Fu \and Tim Menzies \and Xipeng Shen}
% \institute{North Carolina State University, Raleigh, NC, USA
%       Wei Fu \email{w}}
% % \email{fuwei.ee \and tim.menzies@gmail.com \and xshen5@ncsu.edu }

% \thispagestyle{plain}
% \pagestyle{plain}
\begin{abstract}
  \textbf{Context:}
  %For  large systems (e.g.  projects run by government or
%defence departments), it is common to lobby for the development funds prior to commencing the work.
%For such software systems, it is important to have an (approximately) accurate    early lifecycle effort estimate % since (1)~large sums of money are involved and (2)~once funds are allocated, it can be problematic
%to lobby for further funds. However, before the software is built, the size of the final system is not
  %known.
  Boehm cautions that early lifecycle estimates of software size
  can wrong by up to a factor of 400\%. This is a
  major concern for software effort estimation methods that use such ESP
  (\underline{e}arly lifecycle \underline{s}ize \underline{p}redictions)
  for their predictions.\\
  \textbf{Objective:} To understand the impact of  bad ESP on software effort
  estimation. .\\
\textbf{Method:} Explore repositories to determine the space of actual software
size estimation errors seen in practice.  Using the results of the first point, conduct
analytical and perturbation-based  analysis of software
effort models that reply on ESP. \\
\textbf{Results:} (a)~ESP errors are far smaller than   feared by Boehm:
while some
projects have estimate errors over 300\%, most
projects have estiamte errors under  80\%. 
(b)~When perturbing size values within those ranges,
effort models 
only a modest increase in effort estimates error: e.g. 39\% to 44\% in the  median magnitude of relative error. (c)~An analytical evaluation of one effort
model (COCOMO) explains why this might be so:   errors in ESP
are dwarfed by the product of all the other factors.\\
\textbf{Conclusion:} (a)~Bad ESP can lead to poor project effort estimates. (b)~However,
the size of that effect is much less than commonly believed.
(c)~Contrary to prior belief, bad ESP {\em not} the dominate factor leading to inaccurate effort estimates.
\end{abstract}
\end{frontmatter}

% % A category with the (minimum) three required fields
% \vspace{1mm}
% \noindent
% {\bf Categories/Subject Descriptors:} 
% D.2.8 [Software Engineering]: Product metrics;
% I.2.6 [Artificial Intelligence]: Induction

 
\vspace{1mm}
\noindent
{\bf Keywords:} effort estimation, size estimation, parametric models, COCOMO.
%  \maketitle 
\pagenumbering{arabic} %XXX delete before submission

\section{Introduction}
Poor software effort estimation can crippled a project.
In
the worst case, over-running projects are canceled and
the entire development effort is wasted. For example,
NASA canceled its incomplete Check-out Launch Control
System project after the initial \$200M estimate was
exceeded by another \$200M~\cite{clcs03}.

Even after decades of research and model
development, there extensive debates as to which
methods are best.  For example, Shepperd et
al. prefer analogy-based estimation (ABE)
methods~\cite{Shepperd1997}.  Meanwhile, within the
United States Department of Defence and NASA,
parametric effort models like
COCOMO~\cite{Boehm1981} are used extensively and
have found to be quite effective~\cite{Lum2002}.
Also, advocates of agile and devops methods prefer
the planning poker method (discussed in \tion{xxx}).
Finally Jorgensen et al.~\cite{jorgensen09} prefer
expert-based approaches where estimates are derived
by committees of human experts.  For studies
comparing these methods, or how to usefully combine
them, and how to reduce errors when they are used,
see~\cite{koc11b,Minku2013,garg15,me13a,koc11b}.

When these methods are debated, it is usual to discuss problems with {\bf Early Sizing Prediction} (ESP),
specifically:
\begin{quote}
 {\em Is it possible, early in the software lifecycle,
    to accurately estimates the size of the final system?}
  \end{quote}
Note that when such estimates are wrong, then any prediction made from that estimate
will also be wrong. This problem is particularly acute for parametric effort estimation
methods such as Boehm et al.'s COCOMO software effort estimation model.
The core of COCOMO  is an estimate that is exponential on KSLOC (thousands of SLOC); i.e.
\begin{equation}\label{eq:one}
\mathit{effort} \propto \mathit{KSLOC}^{\; n}
\end{equation}
In 1981, Boehm~\cite{boehm81} warned that ESP can be wrong by up to 400\%.
Note that, if such erroneous values were used in \eq{one}, then due to the $ \mathit{KSLOC}^{\; n}$
term, this would lead to  exponentially large errors in the estimate.

Since 1981, much has been learned about software
engineering. Accordingly, it is time to revisit
Boehm's pessimism about bad ESP.  We find that bad SE is far less problematic that suggested
by Boehm.
To show this, this paper explores three research questions
using a simulation study, an analytical study, and a theoretical study.
\bi
\item
{\bf RQ1 (the simulation study): What is the observed impact of bad ESP? }
Given a model producing an estimate, we record the size of the error
in the estimates
after perturbing the size estimates by some factor $\Delta$.
\ei
\begin{lesson}
We find that for the range of $\Delta$ seen in contemporary projects, this error
is usually negligible. That is, 
the
problem of bad ESP is much less than previously
feared.
\end{lesson}
Note that the key part of the {\bf RQ1} analysis is determining the
range of $\Delta$ seen in contemporary projects.
To obtain that range, we used data from 64 recent projects (14 from NASA, 50 
from the United Science Department of Defense). 
This introduces an external validity problem since our answers to {\bf RQ1} are
only good for the values seen in these 64 projects. Therefore, to extend the external
validity of our conclusions:
\bi
\item
{\bf RQ2 (the analytical study):   What is the range of possible effect of bad ESP ?}
For this question, we studied the coeffecients within a parametric effort
estimation model (COCOMO~\cite{boehm81,boehm00b})  to derive minimum and maximum
effects of changes to the KSLOC coeffecient in \eq{one}.
\ei
\begin{lesson}
Given tuning data  from 254 projects, we show that the
  exponential term $n$ is very small: specifically,
  \mbox{$1.06 \le n \le 1.3$}. That is, ESP errors have such a low coefficient that ESP errors
  results in linear, rather than exponential, errors in the predictions.
  \end{lesson}
 The results for {\bf RQ2} is based on more projects than {\bf RQ1}, but it is still
 a small sample from the space of all possible software projects. Accordingly, we conducted
 one more study:
  \bi
  \item
  {\bf RQ3 (the theoretical study): Ignoring all tunings, what is the net
    effect of errors with KSLOC estimation versus errors in other attributes?}
 This theoretical study applies some algebraic manipulations to the COCOMO model
 to derive an expression that comments on the relative effects of KSLOC errors
 to all the other 22 attributes in the COCOMO model.
 \ei
 \begin{lesson}
  Within the COCOMO model,
  KSLOC errors are {\em not} the most influential attribute on effort estimates
 since errors in KSLOC are easily
 dwarfed  by the effects from the other 22 COCOMO attributes.
 \end{lesson}
 Our conclusion from the above is that,
 for the COCOMO model, the results from {\bf RQ1,RQ1,RQ3}  show that there is little reason
  to fear alarmingly large estimation errors due to ESP errors. This is an important contribution since
  one of the standard critiques of COCOMO is its dependency on ESP.

  As to impact of bad ESP on other estimation frameworks, we leave that for future work.
  That said, the methods of this paper could used be used to  certify that some effort
  estimator  is not prone to bad ESP
  errors.  The simulation study described above
   could be applied to any other
   effort estimation method. Also, for parametric estimation methods, it would also be possible to apply
   the theoretical study and the analytical study  (caveat: but
   note that the analytical study requires access to project data in order to understand the space of
  usual model values).
  
  The rest of this paper is structured as follows.
  
\section{Background}

\input{Tables/cocomoParams}
  
  \subsection{COCOMO Details}
  Our experiments are based on the COCOMO model.
  One reason to study parametric models like COCOMO is that they are used and supported
extensively in commercial practice:
\bi
\item
In our work with the Chinese and the United States software industry,
we saw an   almost exclusive
use  of parametric estimation tools such as those offered by 
Price Systems (pricesystems.com) and  Galorath (galorath.com).
\item
Professional societies, handbooks and
certification programs are mostly developed around 
parametric estimation methods and tools; e.g. see the 
International Cost Estimation and Analysis Society; the
NASA Cost Symposium;  the
International Forum on COCOMO and Systems/Software
Cost Modeling\footnote{See the websites \url{http://tiny.cc/iceaa}, \url{http://tiny.cc/nasa_cost}, \url{http://tiny.cc/csse}}.
\ei
  COCOMO was developed in two states: an initial release in 1981~\cite{boehm81}
  followed by an extensive revision in  2000~\cite{boehm00b}.
  In between those releases,
  Boehm created a consortium for
industrial users of COCOMO.
This consortium
collected information on 161 projects from commercial,
aerospace, government, and non-profit organizations.
Using that new data, in 2000, Boehm and his colleagues developed
a set of   {\em tunings} for COCOMO-II that
mapped the project descriptors (very low, low, etc)
into the specific attributes used in the COCOMO model (see \fig{cparems}).
Those tunings, mappings, and attributes became the COCOMO-II model
released 
\begin{equation}\label{eq:cocII}
\mathit{effort}=a\prod_i EM_i *\mathit{KLOC}^{b+0.01\sum_j SF_j}
\end{equation}
Here, {\em EM,SF} are  effort multipliers and scale
factors and
 $a,b$ are the {\em local calibration} parameters (with default values of 2.94 and 0.91).
 In COCOMO-II, effort multipliers change effort by a linear amount
 while scale factors change effort by an exponential amount.
COCOMO-II reports {\em effort}
as ``development months'' where one month
is 152 hours of work  (and includes development and management hours).
For example, if {\em effort}=100, then according to COCOMO,
five developers would finish
the project in 20 months.




 \subsection{Alternatives to COCOMO}

 
COCOMO was initially designed in the age of
waterfall development where projects developed from
requirements to delivery with very little
operational feedback.  Hence, a frequently asked
question about this work is the relevancy of that
$20_{th}$ century software management tool to
current practices.  At issue here is the core
question addressed by this paper.  While there is
nothing inherently ``waterfall'' within the COCOMO
equations, COCOMO does assume that a size estimate
is available before the work starts.  Hence, it is
important to understand when changes to the size of
the software results in inaccurate COCOMO estimates.

Another complaint against the COCOMO equations is
that such ``model-based'' methods are less
acceptable to humans than ``expert-based methods''
were estimated are generated via committees of
experts. The advantage of such expert-based methods
is that if some new project has some important
feature that is not included in the COCOMO
equations, then human expertise can be used to
incorporate that feature into the estimate.
However,
such expert-based approaches have their limitations.
Valerdi~\cite{valerdi11} lists the cognitive biases
that can make an expert offer poor expert-based estimates.
Passos et al. offer specific examples for those
biases: they show that many commercial software
engineers generalize from their first few projects
for all future projects~\cite{passos11}.  J{\o}rgensen
\& Gruschke~\cite{jorgensen09} offer other results
consistent with Passos et al.  when they document
how commercial ``gurus'' rarely use lessons from
past projects to improve their future
expert-estimates.  More generally,
J{\o}rgensen~\cite{Jorgensen2004} reviews studies
comparing model- and expert- based estimation and
concludes that there there is no clear case that
expert-methods are better.  Finally, in 2015,
J{\o}rgensen further argued~\cite{jorg15} that
model-based methods are useful for learning the {\em
  uncertainty} about particular estimates; e.g.  by
running those models many times, each time applying
small mutations to the input data.

 One expert-based estimation method preferred by advocates of
 agile/devops is ``planning poker''~\cite{molokk08}
 where participants offer anonymous ``bids'' on the
 completion time for a project. If the bids are
 widely divergent, then the factors leading to that
 disagreement are elaborated and debated. This cycle
 of bid+discuss continues until a consensus has been
 reached.  Despite having numerous advocates,
 there are very few comparative studies of planning
 poker vs parametric methods. The only direct
 comparison we can find is the 2015 Garg and Gupta
 study that reports planning poker's estimates can be
 twice as bad as those generated via parametric
 methods~\cite{garg15}. One reason for the lack of
 comparisons is that COCOMO and planning poker
 usually address different problems: \bi
\item COCOMO is often used to negotiating resources prior to starting a project;
\item Planning power is often used to adjust current activity within the resource allocation of a project.
  \ei
  \subsection{Problems with Size Estimates}
Combining the last two points, we note that there no real dispute between planning poker (that is an intra-project
task adjustment tool) and COCOMO (which is an pre-project tool for checking if enough resources are available
to start a project).
That said, COCOMO does rely on an early lifecycle size esimate which, according to Boehm~\cite{boehm81}, can be wrong
by up to 400\%.
Such size estimates can be expressed in several
forms including function points~\cite{Albrecht83} of  source lines of code (SLOC)~\cite{boehm81}.
But no matter how  these size measures are expressed, early in the software development process,
ESP can be inaccurate for many reasons such as:
\bi
\item How was reused code accounted for in the size estimate?
\item  Was size measured from end-statement or end-of-line?
\item How were lines of comments handled?
\item Given systems built in multiple languages, how were sizes from different programs translated
  into a single number?
\item
  Given any kind of iterative development, how will feedback learned during the development change
  the goals of the project and the size of the delivered system?
  \ei
  
 

\section{Methods}
These section explores three research questions:
\bi
\item[{\bf RQ1:}] In practice, what are the actual sizes of errors in early life cycle size estimation?
\item[{\bf RQ2:}] Using simulation studies, what are the impacts on estimates of errors of those actual sizes?
  \item[{\bf RQ3:}] In theory, what are the actual sizes of errors in early life cycle size estimation?
    \ei

    To find the actual sizes of size estimate errors needed for {\bf RQ1}, we explore the proceedings
    of NASA and US Defense Department 

    \begin{figure}
      \scriptsize
      \begin{minipage}{.5\linewidth}
      \begin{tabular}{r|rr|}
   project & pre-analysis&pre-coding\\\hline
a&-44\%&-44\%\\
b&-13\%&-4\%\\
c&-6\%&-6\%\\
d&-4\%&-4\%\\
e&5\%&5\%\\
e&7\%&\\
f&10\%&10\%\\
g&54\%&54\%\\
h&64\%&64\%\\
i&69\%&69\%\\
j&78\%&78\%\\
k&95\%&52\%\\
l&206\%&10\%\\
m&236\%&236\%
      \end{tabular}\end{minipage} \begin{minipage}{.33\linewidth}
        \includegraphics[width=1.8in]{nasadata.png}
        \end{minipage}
      \caption{Errors in estimates of final system size (measured in terms of LOC)
        seen before analysis and coding in 14 NASA projects. Values in the left-hand-size table
        are shown graphically at right.
        All percentages here are percents on the final code size. For example, in the last
        line, Project M's final size was 236\% larger than predicted at the pre-analysis stage.
        Positive values denote initial under-estimates while negative values denote over-estimates
        (e.g. the size of the first four projects were initially over-estimated). Note
        that none of the values shown here come close to Boehm's ``incorrect by 400\%'' figure;
        in fact- of the 28 estimates shown here, $\frac{24}{28}\approx 86$\%
        only four are more than 80\% incorrect.}
        \label{fig:loc}
    \end{figure}

    50 Programs
    Mission types:
    \bi
  \item 31 Command and Control;
    \item 6 Office Automation, Software Tools, Signal Processing;
    \item 5 Database, Diagnostic, Mission Plans, Simulation, Utilities;
    \item 5 Testing;
    \item 3 Operating System;
      \ei
      
      Development processes:
      \bi
    \item 15 Waterfall;
    \item 12 Incremental;
    \item 8 Spiral;
    \item 15 Undefined
      \ei

      {\scriptsize
      \begin{tabular}{r|r|r|r|r}
      Complexity & N &  Product Line  & Environment & State of the Art\\\hline
Simple& 2& Existing& Existing &Current\\
Routine& 10& New& Existing& Current\\
Moderate& 14& New& New& Current\\
Difficult& 24& New& New& New\\
\end{tabular}}

        
 \section{Methods}
 To check the effects of noise, we repeated the reduction
experiments of the last section while also injecting
noise into the KLOC values.
That is, as above, 
(1)~the ranges were reduced to three;
(2)~half the columns were reduced;
(3)~we trained on only eight randomly selected projects; and 
(4)~prior to train and test, all KLOC values were adjusted
to
\[\mathit{KLOC} = \mathit{KLOC}*((1- n) + (2*n*r))\]
where $n \in \{0.25,0.5\}$ is the level of noise we are exploring and $r$ is a random number
$0 \le r \le 1$.

In \fig{noise}, any result
marked with {\em n/2} or {\em n/4} shows what happens
when the KLOCs were varied by 50\% or 25\% respectively.
In only one case (COC81) were the noisy results statistically
different from using data without noise. That is,
the parametric estimation method being recommended here is
not unduly effected by noise where the KLOC values
vary up to 50\% of their original value.

 \section{Results}
 
 
 
\begin{table}[!htpb]
\centering
\caption{NASA10}
\scriptsize
\label{tab:nasa10}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Name}}} & \multicolumn{2}{c|}{\textbf{Mean}}     & \multicolumn{2}{c|}{\textbf{Variance}} \\ \cline{2-5} 
\multicolumn{1}{|c|}{}                               & \textbf{Rank} & \textbf{Med $\pm$ IQR} & \textbf{Rank} & \textbf{Med $\pm$ IQR} \\ \hline
COCOMO2                                              & 1             & 43 $\pm$ 35            & 1             & 0 $\pm$ 0              \\
0.2:COCOMO2                                          & 1             & 38 $\pm$ 32            & 1             & 1 $\pm$ 1              \\ \cline{4-5}
0.4:COCOMO2                                          & 1             & 45 $\pm$ 40            & 2             & 2 $\pm$ 2              \\ \cline{2-3}
0.6:COCOMO2                                          & 2             & 49 $\pm$ 30            & 2             & 4 $\pm$ 2              \\ \cline{4-5}
0.8:COCOMO2                                          & 2             & 49 $\pm$ 36            & 3             & 6 $\pm$ 3              \\
1.0:COCOMO2                                          & 2             & 50 $\pm$ 34            & 3             & 8 $\pm$ 7    \\ \hline         
\end{tabular}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[!htpb]
\centering
\caption{COC05}
\scriptsize
\label{tab:coc05}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Name}}} & \multicolumn{2}{c|}{\textbf{Mean}}     & \multicolumn{2}{c|}{\textbf{Variance}} \\ \cline{2-5} 
\multicolumn{1}{|c|}{}                               & \textbf{Rank} & \textbf{Med $\pm$ IQR} & \textbf{Rank} & \textbf{Med $\pm$ IQR} \\ \hline
COCOMO2                                              & 1             & 46 $\pm$ 134           & 1             & 0 $\pm$ 0              \\ \cline{4-5}
0.2:COCOMO2                                          & 1             & 46 $\pm$ 132           & 2             & 2 $\pm$ 9              \\ \cline{4-5}
0.4:COCOMO2                                          & 1             & 48 $\pm$ 131           & 3             & 5 $\pm$ 36             \\
0.6:COCOMO2                                          & 1             & 50 $\pm$ 120           & 3             & 8 $\pm$ 80             \\ \cline{4-5}
0.8:COCOMO2                                          & 1             & 63 $\pm$ 100           & 4             & 12 $\pm$ 130           \\
1.0:COCOMO2                                          & 1             & 65 $\pm$ 113           & 4             & 18 $\pm$ 162 \\ \hline
\end{tabular}
\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[!htpb]
\centering
\caption{NASA93}
\scriptsize
\label{tab:nasa93}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Name}}} & \multicolumn{2}{c|}{\textbf{Mean}}     & \multicolumn{2}{c|}{\textbf{Variance}} \\ \cline{2-5} 
\multicolumn{1}{|c|}{}                               & \textbf{Rank} & \textbf{Med $\pm$ IQR} & \textbf{Rank} & \textbf{Med $\pm$ IQR} \\ \hline
COCOMO2                                              & 1             & 39 $\pm$ 39            & 1             & 0 $\pm$ 0              \\
0.2:COCOMO2                                          & 1             & 39 $\pm$ 36            & 1             & 1 $\pm$ 1              \\ \cline{4-5}
0.4:COCOMO2                                          & 1             & 40 $\pm$ 33            & 2             & 2 $\pm$ 1              \\ \cline{4-5}
0.6:COCOMO2                                          & 1             & 42 $\pm$ 26            & 3             & 3 $\pm$ 3              \\ \cline{2-5}
0.8:COCOMO2                                          & 2             & 44 $\pm$ 23            & 4             & 6 $\pm$ 3              \\
1.0:COCOMO2                                          & 2             & 51 $\pm$ 18            & 4             & 8 $\pm$ 3          \\ \hline   
\end{tabular}
\end{table}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[!htpb]
\centering
\caption{COC81}
\scriptsize
\label{tab:coc81}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\multirow{2}{*}{\textbf{Name}}} & \multicolumn{2}{c|}{\textbf{Mean}}     & \multicolumn{2}{c|}{\textbf{Variance}} \\ \cline{2-5} 
\multicolumn{1}{|c|}{}                               & \textbf{Rank} & \textbf{Med $\pm$ IQR} & \textbf{Rank} & \textbf{Med $\pm$ IQR} \\ \hline
COCOMO2                                              & 1             & 32 $\pm$ 33            & 1             & 0 $\pm$ 0              \\
0.2:COCOMO2                                          & 1             & 32 $\pm$ 32            & 1             & 1 $\pm$ 1              \\ \cline{4-5}
0.4:COCOMO2                                          & 1             & 36 $\pm$ 28            & 2             & 2 $\pm$ 3              \\ \cline{2-5}
0.6:COCOMO2                                          & 2             & 43 $\pm$ 15            & 3             & 4 $\pm$ 3              \\ \cline{2-3}
0.8:COCOMO2                                          & 3             & 49 $\pm$ 23            & 3             & 6 $\pm$ 5              \\ \cline{4-5}
1.0:COCOMO2                                          & 3             & 50 $\pm$ 19            & 4             & 9 $\pm$ 5      \\ \hline       
\end{tabular}
\end{table}

 
\begin{figure}
    \centering
    \includegraphics[scale=0.5]{Figs/mre.png}
    \caption{MRE for effor while varying LOC in different datasets.}
    \label{fig:mre_datasets}
\end{figure}


\section{Why Such Small Changes to COCOMO?}

  
Note that, from \eq{cocII},
the minimum  
effort  is bounded by the  {\em sum} of the minimum scale factors
and the {\em product} of the minimum effort multipliers.
Similar expressions hold for the  maximum effort estimate. Hence,
for a given KLOC, the range of values is given by:
\[
0.18*\mathit{KLOC}^{0.97}  \le \mathit{effort} \le 154*\mathit{KLOC}^{1.23}\]
Dividing the minimum and maximum values results in an  expression showing
how    effort can vary for any given KLOC.: 
\begin{equation}\label{eq:ration}
154/0.18 *\mathit{KLOC}^{1.23 - 0.97} = 856*\mathit{KLOC}^{0.25}
\end{equation}


\section*{Acknowledgments}
The work has partially funded by a National Science Foundation CISE CCF award \#1506586.
 
\vspace*{0.5mm}
 
 
% \bibliographystyle{plain}
\bibliographystyle{elsarticle-num}
% \balance
\bibliography{refs}  

   



%   %%%%parameters for F %%%%%%
% \begin{table*}[!ht]
 
% \resizebox{\textwidth}{!}{
% % \renewcommand{\baselinestretch}{0.9}
% \scriptsize
% \centering
%   \begin{tabular}{|c |c |c |c |c |c |c |c |c |c |c |c |c |c |c |c |c |c |c |c |}
%     \hline
    
%   \begin{tabular}[c]{@{}c@{}}Learner \\ Name\end{tabular}&Parameters  & Default &antV0&antV1&antV2&camelV0&camelV1&ivy&jeditV0&jeditV1&jeditV2&log4j&lucene&poiV0&poiV1&synapse&velocity&xercesV0&xercesV1\\ 
%  \hline
% \multirow{8}{*}{\begin{tabular}[c]{@{}c@{}}Where\\based\\ Learner\end{tabular}}
% & threshold& 0.5& 0.04& 0.44& 0.44& 0.98& 0.65& 0.77& 1& 0.65& 0.98& 0.44& 0.44& 0.87& 0.04& 0.77& 0.24& 0.44& 0.77\\ \cline{2-20}
% & infoPrune& 0.33& 0.51& 0.68& 0.88& 0.47& 0.07& 0.31& 0.48& 0.68& 0.57& 0.12& 0.68& 0.01& 0.51& 0.14& 0.54& 0.68& 0.14\\ \cline{2-20}
% & min\_sample\_size& 4& 6& 4& 6& 1& 6& 8& 8& 4& 6& 7& 4& 9& 6& 2& 8& 4& 8\\ \cline{2-20}
% & min\_Size& 0.5& 0.18& 0.4& 0.56& 0.51& 0.65& 0.59& 0.97& 0.4& 0.51& 0.8& 0.4& 0.77& 0.18& 0.62& 0.46& 0.4& 0.66\\ \cline{2-20}
% & wriggle& 0.2& 0.25& 0.29& 0.76& 0.6& 0.63& 0.26& 1& 0.51& 0.17& 0.36& 0.51& 0.83& 0.25& 0.5& 0.52& 0.29& 0.26\\ \cline{2-20}
% & depthMin& 2& 3& 3& 3& 1& 5& 3& 2& 3& 5& 5& 3& 4& 3& 3& 3& 3& 3\\ \cline{2-20}
% & depthMax& 10& 16& 15& 15& 8& 19& 10& 7& 15& 5& 15& 15& 19& 16& 6& 19& 15& 10\\ \cline{2-20}
% & wherePrune& False& False& True& True& True& True& True& True& False& False& True& True& True& False& True& False& False& True\\ \cline{2-20}
% & treePrune& True& False& True& True& False& False& False& False& False& True& True& True& False& False& False& True& True& False\\ \cline{2-20}
% \hline
% \multirow{5}{*}{CART}
% & threshold& 0.5& 0.34& 0.25& 0.01& 0.01& 0.73& 0.53& 0.92& 0.8& 0.74& 0.54& 0.03& 0.91& 0.01& 0.01& 0.55& 1& 0.01\\ \cline{2-20}
% & max\_feature& None& 0.01& 0.01& 0.29& 0.01& 0.46& 0.75& 0.79& 0.74& 0.41& 0.81& 0.61& 0.72& 0.01& 0.01& 0.01& 0.25& 0.18\\ \cline{2-20}
% & min\_samples\_split& 2& 18& 20& 12& 2& 15& 11& 2& 18& 13& 9& 17& 16& 10& 4& 8& 3& 15\\ \cline{2-20}
% & min\_samples\_leaf& 1& 19& 16& 15& 17& 1& 1& 13& 10& 4& 3& 7& 5& 20& 7& 8& 1& 6\\ \cline{2-20}
% & max\_depth& None& 12& 2& 15& 1& 41& 20& 44& 15& 13& 5& 23& 14& 1& 5& 17& 47& 13\\ \cline{2-20}
% \hline
% \multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Random \\ Forests\end{tabular}} 
% & threshold& 0.5& 0.01& 0.35& 0.3& 0.01& 0.9& 0.97& 0.63& 1& 0.73& 0.68& 0.01& 1.0& 0.01& 0.07& 0.22& 1& 0.82\\ \cline{2-20}
% & max\_feature& None& 0.63& 0.17& 0.01& 0.01& 0.88& 0.74& 0.76& 0.73& 0.01& 0.03& 0.39& 0.02& 0.01& 0.56& 0.36& 0.51& 0.89\\ \cline{2-20}
% & max\_leaf\_nodes& None& 40& 33& 46& 22& 11& 16& 38& 34& 30& 31& 12& 49& 25& 47& 15& 39& 24\\ \cline{2-20}
% & min\_samples\_split& 2& 10& 16& 20& 1& 1& 1& 1& 4& 20& 19& 11& 14& 2& 17& 19& 20& 19\\ \cline{2-20}
% & min\_samples\_leaf& 1& 4& 15& 9& 13& 18& 11& 3& 16& 17& 6& 10& 7& 19& 13& 11& 2& 14\\ \cline{2-20}
% & n\_estimators& 100& 120& 73& 75& 130& 97& 144& 125& 97& 80& 111& 96& 101& 50& 67& 74& 63& 66\\ \cline{2-20}
% \hline  \end{tabular}
% }
%   \caption{Parameters tuned on different models over the objective of ``F''.}\label{tab:fselect}
% \end{table*}
 
  
% \clearpage
% \pagenumbering{roman}
% \setcounter{page}{1} 
% \section*{Reply to Reviews}

% Thank your for your comments. The typos listed by reviewers
% have been fixed and the remainder of the paper has been given
% a careful proof read.

% The reviewers raised certain issues which we respond  to as follows.

% {\em I am concerned about the reproduction of work from elsewhere. Although the relevant paper and book are cited in section 2.3 ([27, 28]) the amount of material that is reproduced is surprisingly large. I am also unsure what "presenting some new results from Rahman et al. [28]" actually means. It would obviously be wrong to present other researchers' results as if newly discovered but I doubt that this is the intention. Indeed, on checking the other paper, there is no obvious overlap. This needs to be clarified.}

% Apologies to the reviewer for our unclear text that suggests
% that this paper inappropriately copied  content from
% elsewhere. This is not the case since nearly all of this paper has not been submitted
% or published to another venue. The exception to that is:
% \bi
% \item Section 2.3 and Table1 contains 1 page of tutorial material which we have adapted from other papers.
% e.g. as the reviewer correctly points out,
% the  'Easy to use' paragraph is taken nearly verbatim from [28], as are the 'widely-used', and 'useful' paragraphs.
% \ei
% Note that apart from Section 2.3,  10 of the 11 pages of this text are   completely new.

% As to the reference to " presenting some new results from Rahman et al. [28]", that refers to one paragraph (120 words) end of section 2.3. 
% Please note that we have removed the misleading text that raised that confusion
% (start of 2.3).

% {\em I think the way that the results are presented does not do justice to the findings in the abstract (that the improvements are large, and the tuning is simple). In particular, tables 8 and 9 are not very clear; why show the naive column?}

% Thank for your that comment- we have simplified that presentation by separating the tuning \#evaluations from the runtimes-- see Table 8 and the new Table 9.

% {\em I am distracted by the frequent use of footnotes. If the material is important and worthy of mention then it should be included in the main body of the paper. However, a reference to the relevant work may be sufficient and is sometimes preferable to using a footnote.}

% Quite true- those footnotes are needlessly distracted.
% They have now been incorporated into the text.



% {\em  Eq 1 - what are d and T? - please use a where clause}



% That where clause is now added after Equation 1. That clause says

% \begin{quote} ... where  $d_i$ is the number of observed issues and $T$
% is some threshold defined by an engineering judgement; we use $T=1$.\end{quote}


\end{document}
 
